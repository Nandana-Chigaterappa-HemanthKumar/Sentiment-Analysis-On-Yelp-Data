{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["pip install pandas scikit-learn torch transformers tqdm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LLItn73qgGJl","executionInfo":{"status":"ok","timestamp":1741399613893,"user_tz":480,"elapsed":11067,"user":{"displayName":"Nandana Chigaterappa Hemanthkumar","userId":"09739011327818673956"}},"outputId":"03a1dd98-3795-4cdc-a2e2-7ef744ed1bcb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.3)\n","Collecting scikit-learn\n","  Downloading scikit_learn-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n","Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2)\n","Collecting transformers\n","  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.65.0)\n","Requirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\n","Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2025.1)\n","Collecting scipy>=1.6.0 (from scikit-learn)\n","  Downloading scipy-1.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n","  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n","Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n","  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.7.1)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2023.12.2)\n","Collecting huggingface-hub<1.0,>=0.26.0 (from transformers)\n","  Downloading huggingface_hub-0.29.2-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n","Collecting regex!=2019.12.17 (from transformers)\n","  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n","Collecting tokenizers<0.22,>=0.21 (from transformers)\n","  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Collecting safetensors>=0.4.1 (from transformers)\n","  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","Downloading scikit_learn-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading huggingface_hub-0.29.2-py3-none-any.whl (468 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.1/468.1 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading scipy-1.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.6/37.6 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n","Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: threadpoolctl, scipy, safetensors, regex, joblib, scikit-learn, huggingface-hub, tokenizers, transformers\n","Successfully installed huggingface-hub-0.29.2 joblib-1.4.2 regex-2024.11.6 safetensors-0.5.3 scikit-learn-1.6.1 scipy-1.15.2 threadpoolctl-3.5.0 tokenizers-0.21.0 transformers-4.49.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"]}]},{"cell_type":"code","source":["import pandas as pd"],"metadata":{"id":"MNqV8Dr1pYrj"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HTKOzbtTohph"},"outputs":[],"source":["train_df = pd.read_csv(\"processed_train.csv\")\n","test_df = pd.read_csv(\"processed_test.csv\")"]},{"cell_type":"code","source":["# Checking for null values in processed files\n","print(\"Null values in train_df:\")\n","print(train_df.isnull().sum())\n","\n","print(\"\\nNull values in test_df:\")\n","print(test_df.isnull().sum())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Q8fA7Ybpi5S","executionInfo":{"status":"ok","timestamp":1741399616152,"user_tz":480,"elapsed":119,"user":{"displayName":"Nandana Chigaterappa Hemanthkumar","userId":"09739011327818673956"}},"outputId":"566ca0c1-c132-4b0a-f452-592fddc62847"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Null values in train_df:\n","sentiment           0\n","processed_review    0\n","dtype: int64\n","\n","Null values in test_df:\n","sentiment           0\n","processed_review    0\n","dtype: int64\n"]}]},{"cell_type":"code","source":["print(train_df.info())\n","print(test_df.info())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"afz4ewORpwbT","executionInfo":{"status":"ok","timestamp":1741399616179,"user_tz":480,"elapsed":26,"user":{"displayName":"Nandana Chigaterappa Hemanthkumar","userId":"09739011327818673956"}},"outputId":"5a209395-db75-4a69-e8c8-c85d8b1610d1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 519951 entries, 0 to 519950\n","Data columns (total 2 columns):\n"," #   Column            Non-Null Count   Dtype \n","---  ------            --------------   ----- \n"," 0   sentiment         519951 non-null  int64 \n"," 1   processed_review  519951 non-null  object\n","dtypes: int64(1), object(1)\n","memory usage: 7.9+ MB\n","None\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 39998 entries, 0 to 39997\n","Data columns (total 2 columns):\n"," #   Column            Non-Null Count  Dtype \n","---  ------            --------------  ----- \n"," 0   sentiment         39998 non-null  int64 \n"," 1   processed_review  39998 non-null  object\n","dtypes: int64(1), object(1)\n","memory usage: 625.1+ KB\n","None\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","# Splitting the train data into train and validation sets (90% Train, 10% Validation)\n","X_train, X_val, y_train, y_val = train_test_split(\n","    train_df[\"processed_review\"], train_df[\"sentiment\"], test_size=0.1, random_state=42\n",")\n","\n","X_test = test_df[\"processed_review\"]\n","y_test = test_df[\"sentiment\"]\n","\n","print(f\"Train size: {len(X_train)}, Validation size: {len(X_val)}, Test size: {len(X_test)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_iLNrdPFpy-z","executionInfo":{"status":"ok","timestamp":1741399616465,"user_tz":480,"elapsed":286,"user":{"displayName":"Nandana Chigaterappa Hemanthkumar","userId":"09739011327818673956"}},"outputId":"29580a36-8d2b-4628-e64e-5d54bd377055"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train size: 467955, Validation size: 51996, Test size: 39998\n"]}]},{"cell_type":"code","source":["import torch\n","\n","# Checking if GPU is available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Running on: {device}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5bqU_QhKrtZo","executionInfo":{"status":"ok","timestamp":1741399617354,"user_tz":480,"elapsed":889,"user":{"displayName":"Nandana Chigaterappa Hemanthkumar","userId":"09739011327818673956"}},"outputId":"d0187815-fa63-4865-a443-158bdb9ac09e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Running on: cuda\n"]}]},{"cell_type":"code","source":["from transformers import BertTokenizerFast\n","from tqdm import tqdm\n","\n","# Loading the fast tokenizer\n","tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n","\n","# Checking if GPU is available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Tokenization Running on: {device}\")\n","\n","def tokenize_texts(texts, tokenizer, max_len=256, batch_size=512):\n","    \"\"\"Tokenizes text in batches and moves to GPU for efficiency.\"\"\"\n","    all_encodings = []\n","\n","    # Processing text in batches\n","    for i in tqdm(range(0, len(texts), batch_size), desc=\"Tokenizing\", unit=\"batch\"):\n","        batch_texts = texts[i:i + batch_size]\n","        encodings = tokenizer(\n","            list(batch_texts),\n","            padding=\"max_length\",\n","            truncation=True,\n","            max_length=max_len,\n","            return_tensors=\"pt\"\n","        )\n","\n","        # Moving the tokenized data to GPU\n","        encodings = {key: val.to(device) for key, val in encodings.items()}\n","        all_encodings.append(encodings)\n","\n","    # Concatenating all the batch tensors\n","    final_encodings = {key: torch.cat([batch[key] for batch in all_encodings], dim=0) for key in all_encodings[0]}\n","\n","    return final_encodings\n","\n","# Tokenizing and moving to GPU\n","train_encodings = tokenize_texts(X_train, tokenizer)\n","val_encodings = tokenize_texts(X_val, tokenizer)\n","test_encodings = tokenize_texts(X_test, tokenizer)\n","\n","print(\"Tokenization completed and moved to GPU!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i9S88cwRsAR5","executionInfo":{"status":"ok","timestamp":1741399693359,"user_tz":480,"elapsed":76003,"user":{"displayName":"Nandana Chigaterappa Hemanthkumar","userId":"09739011327818673956"}},"outputId":"f4534689-868b-4895-a2ac-fc644c2c05c0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]},{"output_type":"stream","name":"stdout","text":["Tokenization Running on: cuda\n"]},{"output_type":"stream","name":"stderr","text":["Tokenizing: 100%|██████████| 914/914 [01:03<00:00, 14.45batch/s]\n","Tokenizing: 100%|██████████| 102/102 [00:06<00:00, 16.72batch/s]\n","Tokenizing: 100%|██████████| 79/79 [00:04<00:00, 16.64batch/s]"]},{"output_type":"stream","name":"stdout","text":["Tokenization completed and moved to GPU!\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n","\n","class YelpDataset(Dataset):\n","    \"\"\"Custom PyTorch dataset for tokenized text data.\"\"\"\n","    def __init__(self, encodings, labels):\n","        self.encodings = {key: val.to(device) for key, val in encodings.items()}\n","        self.labels = torch.tensor(labels.values).to(device)\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        item = {key: val[idx] for key, val in self.encodings.items()}\n","        item[\"labels\"] = self.labels[idx]\n","        return item\n","\n","# Converting the data to PyTorch datasets\n","train_dataset = YelpDataset(train_encodings, y_train)\n","val_dataset = YelpDataset(val_encodings, y_val)\n","test_dataset = YelpDataset(test_encodings, y_test)\n","\n","print(\"Datasets created and moved to GPU!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qfWEwWqssLUp","executionInfo":{"status":"ok","timestamp":1741399693509,"user_tz":480,"elapsed":142,"user":{"displayName":"Nandana Chigaterappa Hemanthkumar","userId":"09739011327818673956"}},"outputId":"3d5a4c1a-8420-4cab-fa2a-ff6e4f7aa998"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Datasets created and moved to GPU!\n"]}]},{"cell_type":"code","source":["BATCH_SIZE = 32\n","\n","# Creating DataLoaders\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=RandomSampler(train_dataset))\n","val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, sampler=SequentialSampler(val_dataset))\n","test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, sampler=SequentialSampler(test_dataset))\n","\n","print(\"DataLoaders ready for training!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YLHbj5nVssmb","executionInfo":{"status":"ok","timestamp":1741399693515,"user_tz":480,"elapsed":4,"user":{"displayName":"Nandana Chigaterappa Hemanthkumar","userId":"09739011327818673956"}},"outputId":"83d4b7ba-232c-49df-addc-4b26ebacc609"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["DataLoaders ready for training!\n"]}]},{"cell_type":"code","source":["from transformers import BertForSequenceClassification\n","\n","# Loading the BERT model with 2 output labels\n","model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n","model.to(device)\n","\n","print(f\"Model loaded on: {device}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CEW7097csxfq","executionInfo":{"status":"ok","timestamp":1741399701280,"user_tz":480,"elapsed":7764,"user":{"displayName":"Nandana Chigaterappa Hemanthkumar","userId":"09739011327818673956"}},"outputId":"6424e1bf-2fac-4d34-f974-c20fc929d579"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Model loaded on: cuda\n"]}]},{"cell_type":"code","source":["from transformers import TrainerCallback\n","\n","EPOCHS = 3\n","PATIENCE = 2\n","\n","class EarlyStoppingCallback(TrainerCallback):\n","    \"\"\"Stops training if validation loss does not improve after `patience` epochs.\"\"\"\n","    def __init__(self, patience=2):\n","        self.patience = patience\n","        self.best_loss = float(\"inf\")\n","        self.counter = 0\n","\n","    def on_evaluate(self, args, state, control, metrics, **kwargs):\n","        if metrics[\"eval_loss\"] < self.best_loss:\n","            self.best_loss = metrics[\"eval_loss\"]\n","            self.counter = 0\n","        else:\n","            self.counter += 1\n","            if self.counter >= self.patience:\n","                print(\"\\n Early stopping triggered! Stopping training.\")\n","                control.should_training_stop = True\n","\n","early_stopping = EarlyStoppingCallback(patience=PATIENCE)"],"metadata":{"id":"wqx8wj0hs4kr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.cuda.amp import autocast, GradScaler\n","from transformers import AdamW\n","\n","# Optimizer & mixed precision training for efficiency\n","optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n","scaler = GradScaler()  # Enables mixed precision, FP16, for faster training\n","\n","def train_model(model, train_loader, val_loader, epochs=EPOCHS):\n","    \"\"\"Trains the BERT model with batch progress tracking & early stopping.\"\"\"\n","\n","    best_val_loss = float(\"inf\")\n","    patience_counter = 0  # Tracking early stopping\n","\n","    for epoch in range(epochs):\n","        print(f\"\\n Epoch {epoch+1}/{epochs}\")\n","\n","        # Training Phase\n","        model.train()\n","        total_loss, total_correct = 0, 0\n","        loop = tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\", unit=\"batch\", dynamic_ncols=True)\n","\n","        for batch in loop:\n","            batch = {k: v.to(device) for k, v in batch.items()}  # Moving batch to GPU\n","            optimizer.zero_grad()\n","\n","            with autocast():  # Enables FP16 for faster training\n","                outputs = model(**batch)\n","                loss = outputs.loss\n","\n","            scaler.scale(loss).backward()\n","            scaler.step(optimizer)\n","            scaler.update()\n","\n","            total_loss += loss.item()\n","            total_correct += (outputs.logits.argmax(dim=1) == batch[\"labels\"]).sum().item()\n","\n","            loop.set_postfix(loss=loss.item())  # Showing live loss update\n","\n","        avg_train_loss = total_loss / len(train_loader)\n","        train_acc = total_correct / len(train_loader.dataset)\n","        print(f\"\\n Training Loss: {avg_train_loss:.4f}, Accuracy: {train_acc:.4f}\")\n","\n","        # Validation Phase\n","        model.eval()\n","        total_correct, total_loss = 0, 0\n","        loop = tqdm(val_loader, desc=f\" Validating Epoch {epoch+1}\", unit=\"batch\", dynamic_ncols=True)\n","\n","        with torch.no_grad():\n","            for batch in loop:\n","                batch = {k: v.to(device) for k, v in batch.items()}\n","                outputs = model(**batch)\n","                loss = outputs.loss\n","                total_loss += loss.item()\n","                total_correct += (outputs.logits.argmax(dim=1) == batch[\"labels\"]).sum().item()\n","\n","                loop.set_postfix(loss=loss.item())\n","\n","        avg_val_loss = total_loss / len(val_loader)\n","        val_acc = total_correct / len(val_loader.dataset)\n","        print(f\"\\n Validation Loss: {avg_val_loss:.4f}, Accuracy: {val_acc:.4f}\")\n","\n","        # Checking for improvement and saving the best model's state\n","        if avg_val_loss < best_val_loss:\n","            best_val_loss = avg_val_loss\n","            patience_counter = 0  # Resetting the patience counter\n","            # Saving the best model's state dictionary in .pt format\n","            torch.save(model.state_dict(), 'BERT_Best_Model_State.pt')\n","            print(\"Best model saved!\")\n","        else:\n","            patience_counter += 1\n","            if patience_counter >= PATIENCE:\n","                print(\"\\nEarly stopping triggered! Stopping training.\")\n","                break\n","\n","train_model(model, train_loader, val_loader, epochs=EPOCHS)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b8aYE1rguIzu","executionInfo":{"status":"ok","timestamp":1741402851701,"user_tz":480,"elapsed":3150402,"user":{"displayName":"Nandana Chigaterappa Hemanthkumar","userId":"09739011327818673956"}},"outputId":"4974fb91-4d71-4f7d-8e66-c5fb1f7763bc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n"," Epoch 1/3\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch 1: 100%|██████████| 14624/14624 [16:11<00:00, 15.05batch/s, loss=0.0144]\n"]},{"output_type":"stream","name":"stdout","text":["\n"," Training Loss: 0.1593, Accuracy: 0.9364\n"]},{"output_type":"stream","name":"stderr","text":[" Validating Epoch 1: 100%|██████████| 1625/1625 [01:16<00:00, 21.22batch/s, loss=0.48]\n"]},{"output_type":"stream","name":"stdout","text":["\n"," Validation Loss: 0.1291, Accuracy: 0.9503\n","Best model saved!\n","\n"," Epoch 2/3\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch 2: 100%|██████████| 14624/14624 [16:10<00:00, 15.07batch/s, loss=0.0323]\n"]},{"output_type":"stream","name":"stdout","text":["\n"," Training Loss: 0.0987, Accuracy: 0.9625\n"]},{"output_type":"stream","name":"stderr","text":[" Validating Epoch 2: 100%|██████████| 1625/1625 [01:17<00:00, 21.01batch/s, loss=0.55]\n"]},{"output_type":"stream","name":"stdout","text":["\n"," Validation Loss: 0.1235, Accuracy: 0.9542\n","Best model saved!\n","\n"," Epoch 3/3\n"]},{"output_type":"stream","name":"stderr","text":["Training Epoch 3: 100%|██████████| 14624/14624 [16:15<00:00, 15.00batch/s, loss=0.151]\n"]},{"output_type":"stream","name":"stdout","text":["\n"," Training Loss: 0.0606, Accuracy: 0.9777\n"]},{"output_type":"stream","name":"stderr","text":[" Validating Epoch 3: 100%|██████████| 1625/1625 [01:16<00:00, 21.25batch/s, loss=0.662]"]},{"output_type":"stream","name":"stdout","text":["\n"," Validation Loss: 0.1435, Accuracy: 0.9514\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n","\n","def evaluate_model(model, test_loader):\n","    model.eval()  # Setting the model to evaluation mode\n","    all_preds, all_labels = [], []\n","\n","    loop = tqdm(test_loader, desc=\"Evaluating Test Set\", unit=\"batch\", dynamic_ncols=True)\n","\n","    with torch.no_grad():\n","        for batch in loop:\n","            batch = {k: v.to(device) for k, v in batch.items()}\n","\n","            outputs = model(**batch)\n","            preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n","            labels = batch[\"labels\"].cpu().numpy()\n","\n","            all_preds.extend(preds)\n","            all_labels.extend(labels)\n","\n","            loop.set_postfix(batch_accuracy=accuracy_score(labels, preds))\n","\n","    return all_preds, all_labels"],"metadata":{"id":"iEQFXPj-uv_f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.load_state_dict(torch.load('BERT_Best_Model_State.pt'))\n","test_preds, test_labels = evaluate_model(model, test_loader)\n","\n","# Computing performance metrics\n","accuracy = accuracy_score(test_labels, test_preds)\n","precision, recall, f1, _ = precision_recall_fscore_support(test_labels, test_preds, average=\"binary\")\n","\n","print(f\"\\nTest Accuracy: {accuracy:.4f}\")\n","print(f\"Precision: {precision:.4f}\")\n","print(f\"Recall: {recall:.4f}\")\n","print(f\"F1-Score: {f1:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gB711rLp9C9E","executionInfo":{"status":"ok","timestamp":1741402911837,"user_tz":480,"elapsed":60133,"user":{"displayName":"Nandana Chigaterappa Hemanthkumar","userId":"09739011327818673956"}},"outputId":"c5f6dac0-3534-4d16-ec00-e2167d8aaed0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Evaluating Test Set: 100%|██████████| 1250/1250 [00:59<00:00, 21.12batch/s, batch_accuracy=0.967]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test Accuracy: 0.9532\n","Precision: 0.9570\n","Recall: 0.9490\n","F1-Score: 0.9530\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"R9IzHG9c9Pk0"},"execution_count":null,"outputs":[]}]}